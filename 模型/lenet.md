---
tags:
  - "#模型类型/CNN"
  - "#任务/图像分类"
  - "#阶段/基础"
  - "#知识域/卷积原理"
---
- LeNet
- 基础地位：经典的卷积神经网络（[[CNN]]），是很多现代深度学习图像任务的奠基模型，适合入门理解 CNN 基本结构。
- 学习步骤：
- 原理剖析：研读 LeCun 1998 年论文《[[Gradient - based learning applied to document recognition]]》，掌握[[卷积层]]（提取局部特征，如边缘、纹理 ）、[[池化层]]（下采样，降低维度，保留关键特征，如最大池化选局部最大值 ）、[[全连接层]]（整合特征做分类 ）的串联结构，理解如何用[[梯度下降]]训练网络完成手写数字识别。
- 代码实践：用[[PyTorch]]/[[TensorFlow]] 实现 LeNet，处理 [[MNIST 数据集]]（手写数字）。搭建网络结构，定义损失函数（如[[交叉熵损失函数]]）、优化器（如 SGD ），跑训练、测试流程，观察训练曲线（损失下降、准确率上升 ），理解模型如何从数据中学到特征。
- 拓展思考：分析 LeNet 在小数据集（MNIST）成功，却难直接用于复杂场景（如高分辨率图像 ）的原因，为后续学更复杂模型做铺垫。


关键遗漏节点：
[[Sigmoid 激活函数]]
 **[[反向传播算法]]**